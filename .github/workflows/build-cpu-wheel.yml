name: build-cpu-wheel-hf

on:
  workflow_dispatch:
  push:
    tags: ["v*"]

jobs:
  build:
    runs-on: ubuntu-22.04
    permissions:
      contents: write
    steps:
      - name: Checkout llama-cpp-python
        run: |
          git clone --recursive https://github.com/abetlen/llama-cpp-python.git
          cd llama-cpp-python
          
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          
      - name: Install dependencies
        run: |
          python -m pip install -U pip
          python -m pip install -U cibuildwheel
          python -m pip install huggingface_hub[cli]
          
      - name: Download test model (optional)
        env:
          REPO_ID: Qwen/Qwen2-0.5B-Instruct-GGUF
          MODEL_FILE: qwen2-0_5b-instruct-q8_0.gguf
        run: |
          huggingface-cli download $REPO_ID $MODEL_FILE
          
      - name: Build wheel (CPU only)
        working-directory: llama-cpp-python
        env:
          CIBW_BUILD: "cp310-manylinux_x86_64"
          CIBW_SKIP: "*-musllinux_*"
          CIBW_REPAIR_WHEEL_COMMAND_LINUX: ""
          CIBW_ENVIRONMENT_LINUX: >-
            CMAKE_ARGS="-DGGML_BLAS=OFF -DGGML_NATIVE=OFF"
        run: |
          python -m cibuildwheel --output-dir ../wheelhouse
          
      - uses: actions/upload-artifact@v4
        with:
          name: wheelhouse
          path: wheelhouse/*.whl
          
      - name: Upload to Release
        if: startsWith(github.ref, 'refs/tags/')
        uses: softprops/action-gh-release@v1
        with:
          files: wheelhouse/*.whl